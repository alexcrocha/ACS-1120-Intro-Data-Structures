Yeah. Oh, welcome back. Hopefully you had that opportunity to review your working histogram data structures that you
wrote. And now I've got like a pretty cool. Little whiteboard diagram here. So let's like use it to, to learn about
these different data structures. Now I asked you in our, in our tutorial, asked to like, write two of these four, there
mentioned that tutorial. So we have our first one. Let me use like a laser pointer here. We have our first one, which
is like the dictionary data structure, right? The second one, which was a list of lists. A list of two bulls. And then
finally a list of count with word lists. And I've also put what a histogram looks like if we were to print it out on
the right hand side of each structure. So a dictionary has these like, you know, curly braces and it's got keys and
values here. We've got a list containing a list. And the first. Index as a value. That's a string. The second index is
a value. That's an integer. Representing the count of the word. We've got one here, which has a list of tubals kind of
the same deal, except the two bull is the structure. And the first index is the string. Word. And the second index is
the. Object or excuse me, the count. And then we had like an even weirder, one of a zoom in here and you can see it.
We've got that list of a word counts, basically a list of counts with word lists. Right. And that would be like a list
structure. And I asked you kind of not, did you this one? Cause it's pretty weird, but we're gonna talk about it
anyway. That one has a list. And inside of it is a two bolt. And the first part is the count. How many we see it. So in
one fish, two fish, red fish, blue fish. One two in red are counted one time. Right? Whereas with fish, it's kind of
four times. We only have one in the list there. Whew. Right on.

Cool. So you should all feel.

Like we've at least got locked on one of them. So we can take some like poll the audience questions. Right. Let's see.
Probably not going to be so easy for me to get like counts of stuff. But let's see if, give me a thumbs up reaction. If
you're able to get the dictionary, the dictionary histogram working.

Very popular. Hmm. About a popular car. Right on just about everyone, like got that one. Okay, cool. How about lists of
lists? Give me a thumbs up. If that was one that you chose and got working list of lists.

Neato about half the room. I feel that that makes sense to me. What about this bad boy? What about the list of tubals?

Y'all might have something to say about that later, which is really cool. Did I get anyone that did like a list of
counts? Did anyone try that one? We have thumbs up. If you tried that. Nice stretch challenge all the way. We'll talk
about how that's relevant in like engineering back in web stuff here shortly. Did anyone do something different? Did
anyone do anything that I haven't named yet?

Nieto that's like sneak preview for more other classes. So we'll talk about other options as well. Cool. So let's start
with our like dictionary datatype and today I want to talk to you about three things. I want to talk about. For each
structure. But they look like. But also what the coding effort is for those. How hard is it? You know, kind of
subjectively intuitively to code. But also, we're gonna talk about our intuitive feelings around time and space.
Efficiency. For each implementation now. This is kind of a sneak preview. We're going to use intuitive answers for this
like faster, slower. But later on in the tutorial later on in class, I will be teaching you formal algorithm analysis.
I'll be teaching you exactly how to do that. You're gonna know how to do it from first principles, you will never need
a big cheat sheet and I will never recommend it because you're gonna know how to do it on anything. And that's really,
really cool. I mean, you can do it on a whiteboard, which is so important. But today we're just been talking about
like, Intuitively are these things like faster, slower? Do they take more time to execute versus do they take up more
room in memory? That's like space efficiency. Maroon and memory is space efficiency, how long it takes to execute time
efficiency. So let's like talk about it. I love that I did pull the audience. There are three options for coding effort
that we're going to talk about today. One's going to be like fast. One's going to be medium. And one's going to be
slow.

Okay. So let's see, is there like a good way to do this? Let's do chats. Coding effort. Let's do like a poll, the
audience button chat, fast, medium, or slow. What do y'all feel about dictionaries? Like take a lot of effort to code.
Did it take a little effort to code? Whew. You also fast with fast.

Fast read on. Okay. Cool. We're going to talk about some of these differences here shortly, but like let's like work on
it fast and straightforward. Nice. Nice. Could I get some commentary on that? Could I get someone like telling us,
like, why is it so fast and straightforward? Why, why do you think that dictionary was like, so. So approachable. Can
anyone tell me.


It just kind of. Oh, sorry. Your hands up. Go ahead. Go ahead.


You've got Brooklyn.


And it just seems like the right application for the use of a dictionary. Like it just made a lot of sense. I mean, we
literally are categorizing words and then we need one thing that counts. So it just made sense to have those key value
pairs.


Right on. And what is it about like the dictionary that, that like allows it to, to be like so easy? What about like
the keys of the dictionary? What do they have to be?

They have to be.

To be unique. Nice Stan, nice Stan. I wasn't really well formed question cause I'm sitting here drawing, but yeah, they
have to be unique, which is why that helped. Right. You get a key error if you like tried to insert another key. So
Python is like super cool about that, right? Like keeps you in check. It checks you before you wreck yourself. Right?
Unique, key and value pairs, which meant we could look it up. Can we look up the word by the key, and then we can just
like increment the value. Pretty straightforward. Nice work. Cool. But let's like, let's actually like rank these like
coding efforts first, and then we'll like do more. How about the list of lists? Is that fast, medium, or slow for all?
Y'all that like, implemented that?

Hmm. A little contention here. Got a little contention read on. You got some fast and some medium. Okay. I'm going to
put medium down. And I'm going to tell you why maybe someone else can tell me why.

Medium. Right. So what was different about implementing a list of lists versus implementing a dictionary? I know I saw
it in chat before, but I want to make sure to call it out. Call it out a little bit. What did you have to do in the
list of lifts? So you didn't have to do in the dictionary loop. Nice work, Omar. Yeah. You had to loop through each
list in the list. Many of you came to me either during office hours or during lab time. Kind of just feeling like. Huh,
this is more effort. Am I doing it wrong? What's going on here? Why are you asking me to do something that requires two
loops? I'm so confused. Daddy. I can write the code, but why are we doing it? Let's like, talk about that now. Right?
So it's required to loop through each list in the list, which means like it's a bit of a medium coding effort, right.
I'm going to have a longer implementation, like physically the code will be longer on the screen. And that might mean
that you have to like, do some extra stuff in the code, like search searching is what required was what made us.
Searching for that word and determining if it already existed in our list was what made it slower. You made it a medium
coding effort, right? Cool.

We'll talk more about this differences here soon, but what about that list of two bulls? I know there were a couple of
people that did that was that like fast, medium, or slow coding effort.

Getting some medium, getting some slow, getting some slow and mediums. I feel that I feel that.

Okay. So let me like change these up actually a little bit. Let's say instead of like fast. I actually usually avoid
these words, like, like the plague. So I don't normally say them, but I'm gonna say I'm here. E Z.

Needy.

Hm. There's a little contention here. I'm going to say it was kind of hard, right?


It'd be hard or really hard or.


Right, right. Hardest is probably what I'd say for the next line. Since you mentioned that now. Harvard. This.

Whew. Okay. Now let's like dig in a little bit. Let's dig in. What is it about the list of tubules that makes it just a
little bit tougher than the list of list? Does anyone have any ideas? Wow. Nice. Tubules are immutable. For those of us
that haven't taken fancy science club. Like a fancy computer science classes. What's a mutable mean?

What's a mutable mean can't be changed. Nice. Can't change it. Very good. Very good. Static is another word. Love at
George. Yeah. If you've been programming before static is going to be like the word you use for that, for sure. Let's
like make some notes about our structures now that we're like learning about this. So a list of two bulls. George
mentions is a static, static array.

Nice, but what's the list of lists. Is it mutable or immutable? In comparison.

Mutable or immutable. Udall. Nice. And so mutable is the opposite of immutable. And the opposite of static is can you
tell me.

Nice dynamic. Arthur killer. Great work. We were like really filling this thing out now. I'll list of list is a dynamic
gray.

Pillar.

Love it. Dynamic array suite. Huh. This thing does not broadcast the grid lines the same way that I thought it would.
Oh, nice. Now we can kind of see him so little, like low Rez, whatever you can see it. Anyway. We've got a dynamic
array for the list of lists. We've got a static array for the. List of tuples. Can anyone tell me what structure a
dictionary is? Formerly? Does anyone happen to know that there's like a word for it? We're going to talk about it like
a lot in this class, anyone know.

Hash table. Nice work. Jane sneak preview hash table.

Nice. So it's going to like be important here soon. We're going to talk about that. Okay. So now we've got three
structures, primarily that y'all implemented either the hash table, the dynamic array or the static gray. Hash table
being easiest because of Y. We talked about that. What makes the hash table or exceeding the hash table or the
dictionary a little bit easiest, like easier.

Can anyone tell me.


That's like a built‑in search functionality.


Nice or I would kind of like if I could rephrase it just a tiny bit. The fast key lookup, right? We're able to look up
the key really quickly. We can do something like if. One in words.

Them. That items, whereas dot items, like so easy to like, figure it out, right. The unique keys, you don't need to
loop to locate, locating to entries. Absolutely. So when we talk about time efficiency, when we talk about time
efficiency, We're talking about intuitively like how long does this take to execute? I want you to think about like,
Your big page, maybe you did like three pages of a Harry Potter book or something, or he did like, I don't know, one or
two Rick and Morty scenes for your sample text.


When


we think about that, is it like fast, medium, or slow in terms of time?

Is the easiest also the fastest, well, that's why we're making this chart. Brooklyn. Are they going to have this sharp
forever? And we're going to know it was easy and fast, right? Cool fast as Dylan fast as Dylan. Let's let's do that
right here. Fast.

And there's a reason for that. It's because you have some fast lookup by key, right?

Oops.

Nice. It's fast. Cause we look stuff up by key. It's like totally built in some like totally genius Python programmers
made it so that we have this accessible hash tables already built. It's already fast. It's already optimized by
bajillion people. They're totally genius mode. And we're able to look stuff up quickly by key. Year to learn how to
implement these from scratch. Of course, cause it's CS class. But he used the dictionary and your first implementation.
Nice work. Now let's think about the time efficiency, how fast something is. What about that list of lists? I remember
like someone saying like it's medium difficulty, but was it faster, slow, slower. If it's slightly slower. Or big,
slower, right? And it's the searching. It's the searching or what you y'all called looping multiple loops. That made it
slow. So when you see those multiple loops where you're trying to find something, can I get that in your vocabulary?
You're searching. Cause that's like a really common algorithm word. Okay. He did see us 1.3 with me, like the verse for
stuff we do is like, Search stuff and we do trees. So really important. So. In this case, when we have a list of lists,
the searches like slow.

Is it better than, or worse than a list of tubals do you think. Just put it in. Chat is a list of lists better. Ooh. I
feel like I'm getting some betters.

Hmm, how. Whole contention. I love the contention. Okay. Let's have list versus list of two bulls. Got lots of
contention here. Let's take this chance now. Let's do a three minute breakout room with your friends and come back with
a unanimous vote. Is a list of lists. Faster regarding time efficiency or slower than a list of tuples and why. And
take five minutes to figure out why. You should be using some of those words that I have written down here. Static
dynamic mutable, immutable. So let's take a second and let's like, I'll try and get on the same page with the wise.
We'll do a five minute breakout room.


With your friends.


Go ahead. Yeah. All right, folks. I asked you in breakout rooms to decide.

Which was, which was faster in terms of time. Efficiency the list of lists or lists than to both. What do we got folks
drop it in chat? What have we decided together?

At two bulls tuples. Hmm. Interesting. Right on. All right, let's talk about it. Let's totally talk about this. So we
got, when we got a list of lists is we've got a list which is a mutable dynamic data structure. That also contains a
bunch of mutable dynamic data structures. Okay. So that means an immutable and dynamic data structure. What gets
allocated in memory is a little bit extra space. So that's like draw it out, like a cute little representation of it
right here. So it gets allocated and memories just. A little bit of extra space. Let's make some blocks here.

Right. So in my little, in my list of lists, what I'm showing you is what gets, what gets. In initialize, we've got a
little bit of extra space here in this mutable data structure, because we can add more to it. It's supposed to be.
Resizing data structure. So when we have just two things in that list, we're gonna have a little bit of extra room. You
can think of it as like I'm when you're in the classroom and like not all the seats are filled, right? Our classroom is
our list data structure, and not all of the seats are filled because some people might join us. Right.

Okay. Then you can think of this two bull data structure. Now two bulls are an immutable static data type, which means
what gets allocated is exactly what the programmer tells. The interpreter to get allocated. Check this out. Which means
if we were to draw an example of what that looks like in memory, it's just two boxes, right? Pointing to one, pointing
to one. Both are used. No extras. Okay. So considering that this list of lists has extra space to it. And considering
that the list of tubals has.

No extra space. The list of list is slightly faster than the list of tubals. Slightly faster than number three on our
list.

Slightly faster than number three, whereas. The. List of tuples here. Sorry. My, my notes are getting covered up. Boop.
It's just slightly worse. The number two, just slightly worse than number two.

Whoops. Did I write the wrong thing? I sure did. Let's fix that. Oh, wow.

We can all agree that the search is slow no matter what.

Slightly worse. The number two, which is our second one here. 1, 2, 3, 4. So you know what I'm referencing here. So
slightly worse than number two, slightly better than number three on time efficiency. We're gonna talk about space
efficiency soon. What about our last one here? Where we like do this crazy? A list of counts for our Dougal sized
datasets. Literally, we probably use this in the case where, oh my gosh, I'm thinking of something crazy. Like what if
we wanted to keep track of the frequencies of words? For the whole entire internet. We might use a data structure. Like
the one that you see right here. Okay. So what about this one with time complexity or the time efficiency for this?

Fast, medium or slow. What have we got here? But in chat. Fast medium or no. Yeah. I mean some slow here. I'm going to
agree with the answers though. In fact, it's going to be the slowest one in our list. Because it's going to be like
really hard. We got to like, look. Now look at a really interesting way. We've got to iterate through the list. We've
got to look at the second index of each tool. We've got to decide in that list. If those words exist there, it's going
to be slower to execute. Cause there's a lot of stuff going on. So let's put the slow in this column here.

Right now we're going to see how like, Each of these things lines up when it comes to spacious space efficiency. And
then we're gonna talk about how there isn't just one right. Tool for the job. So right now, if you're thinking. Well,
obviously like dictionaries are the best. We all use dictionaries for everything forever.

Hold on to that. Hold on. That idea, because computer science is all about choosing the best tool for the job. You can
use a hammer to hit the nail. That's the most efficient thing. Some people choose the end of a screwdriver to pound in
that nail. It's not as efficient, but it works right. So let's talk about choosing the best tool for the job. When we
come to.

Dictionaries when it comes to space, when I say space. So we need to think of how much memory is being used by the
computer. When it comes to space efficiency, is it the best? Or the worst here.

Or is it just in the middle? Because this is a dictionary. The best or the worst. Or hash table.

Hmm, right on. Got some folks thinking like, Ooh, worst in terms of space, there's a lot of things a hash table needs
to do in order to efficiently store your data. It's got to go through like all whole process. Y'all seriously, all
whole process. It's crazy. Right. And learn about all, about all, about it. And CS 1.3. But trust me when I say that
there are a multitude of processes that cause lots of overhead, like Dylan said, And that's what makes it the worst in
terms of space complexity.

Whoa. So the thing that's easiest to code, that's the fastest to execute. It takes up more memory. Interesting. There
are always trade offs and you see it here in our diagram first.

Now let's think about. The other end of the spectrum, which one on our list.

Dictionaries lists of lists, lists of tubules, or even like the fourth craziest one. Which one do you think is the
best?

Do you think is the best in terms of memory storage?

Hm.

Hamm's a drop in the four. I haven't heard from you yet. Tell me why you think like four is the best in terms of like
storing computer memory. Like what makes it the best?


Because it looks the most organized at all of them.


Oh, I love that. That's like a nice, intuitive answer. It's a really organized. Additionally, I'm like. Kind of
condensing it, right.


I'm saying all of these words


are counted. They have one instance in there and like all of these words, they have four instances in their fewest
repetitions. Oh, I like that. Very nice. Totally. Totally.

All right.

Oh, that's the wrong pen. Best. Nice. Now we need to differentiate between the list of lists and lists of two bulls.
But we want to find out is which ones like better or worse in terms of storage?


And you read into them green.


Oh, why is it in red instead of green? That's probably a good, a good note there. This should be best.

Best nice. I like a good color coded diagram, obviously. Good. Looking out Hamza. Let's see. Do you think.

Remember, considering that the list of lists is a mutable data structure with extra spaces allocated. Do you think it's
better or worse than a tubal?

Better where space efficiency.

Let's do tables is less storage. Where's nice. Yeah. It's worse because it's got extra spaces. Yo. Look, there's two
seats in the classroom. Every time I have that list, there, two extra seats. Whereas with this tubal there isn't two
extra seats. When you use that analogy a whole lot more later on when I talked to you about these different things.
Yeah. It's worse.

Then. Number three.

For sure. And better than number two.

Yeah.

Nice. Shake it out. So we've got.

Everything pretty much written down. We know that like the easiest and fastest thing, which is like a dictionary or
hash table ends up being like the one that takes up a lot more memory in our computers. Because of like all this cool
hash table stuff that I can't wait to teach you. As soon as the tutorial, you just have to trust me for now. Notice how
we're doing like intuitive answers on time and space efficiency. We're not doing big O yet. But intuitive answers. Our
lists stored in a tubal immutable.

They're immutable list stored in a tubal or mutable. I recall correctly, I'm actually have to like write some code to
be 100% sure of that. Arthur.

Because different languages like to do different things. And I like said that was so much confidence about Python, but
I'm like no, a lot of languages. So I'm going to like, actually write that question down and I'll get back to you after
break. That'll be like a cool thing to discuss for sure.

All right. Now. I want you to know that there's like other ways to solve the problems that we dealt with in the third
page of the tutorial, when we were creating histograms as well. We could think of like, maybe like down here on five.
There could have been a situation where you decided to sort your list of lists or your lists of tools, things like
binary search might be like the thing that helps if you don't know what that is, stick around for CS 1.3 with me, I
hope it's next term. We'll be talking about binary searches. It's like one of the very first things we do. So we could
like when we're searching through that list, a binary search just means split it up into right. We could split it up.
And we could say for a word that starts with F it's going to be in the first half of the list. We only have to search
that first half of the list. But if a word starts with X, it's going to be the second half of the list. You only have
to search the second after the list. So it's sorted. List of words would be pretty dope. Because then we wouldn't have
to search through so much.

And so on and so forth, there are actually many, many ways to do this. So we can see here. That no matter what it's all
about choosing the best tool for the job. And you're going to apply structures like this throughout the course and
throughout your lifetime. Where you need to make trade‑offs. For example, like I remember there was someone in Java
said it's okay. There's like a lot of memory on computers nowadays or something like we have like lots of memory. Ah,
but what about the case where I say something like. Okay, now I need you to. Index or keep track of all of the words,
the count of all the words that have ever been used on the internet.

Boy, I guarantee you even on like my super fancy Mac book pro like with a bajillion gigabytes of Ram 64. Okay. That's
actually extremely difficult to store that kind of data. In fact, it has like, For problems like that, we use like kind
of a modified version of what I've circled here. All right. So there might be different data structures depending on
the. On your big data versus small data, right? Big data versus small data. You might want something like a list of
lists because as a programmer, you're really comfortable coding that. And at the end of the day, getting the job done
is really important. So you choose like the easier medium coding effort. One. Even though search is a little bit slow,
right? You have to do a linear search. You got to check everything.

Same as like, maybe you're actually really familiar with immutable data structures. You choose that because that's a
comfortable thing for you to code. It's like slightly slower to execute than a list of lists, but it takes up less
space. Right. So oftentimes there's many reasons why you might choose the best tool for the job. Comfort. Number one
comfort level. When it comes down to the end of the day, you got to get something working in the real world. There's a
lot of you're dead. You chose a dictionary, felt super comfy. You got something working in the real world, but you
didn't know that it took up a bunch of space. On your computer when you did it. Whereas for some of you, you're like,
eh, you know, I feel pretty comfortable with like, listen 1.1. No, let's just do some lists. That'd be dope. He felt
comfortable kind of searching through, but it was a little bit harder. I know I helped a lot of little light helped.
Y'all a lot with like some like little linear search algorithms to feel comfortable or just to coach you through. Yes.
This is what I want you to do. I do want you to search through all the words.

So. TLDR. Everything's a trade‑off in computer science. There's no one best answer. But we're gonna move forward with
this and we're gonna use our data structures. With.

The next page of the tutorial and I teach you. Basically how to take like your random words or your like words that you
got that like don't really make sense or don't show up that frequently. We're going to actually look at your data set.
We're gonna look at your list of words, determine which words show up most. And then we're going to use those words
more frequently in our output. This is really important. Like I said before, if we're reading a Harry Potter book and I
like, don't see the word Harry, in one of the sentences we generate, that's kind of like a little weird, right? It was.
It's a frequently occurring word. I'm also going to teach you how to get rid of the really annoying where it's like a
and de. Later on. All right, let's take a quick break. If you have any questions, hang on to them for after break. I
will answer each and every one. And. Let's come back here. Around 5 45. And we will introduce the next part of our
lecture, which is. They're a little bit about probability, so that'll be fun. All right, folks. I'll see you soon. Come
back at 5 45.

All right, folks that he got me in your years and you haven't yet. Come back. Let's make sure to do that.

Gotta re hook up my monitor here.

Cool.

Welcome back folks. We're going to dive into the last half of our lecture, which is on probability.

Give me a sec just to like play these slides. Let's switch a switch. It.

Oops, there we go.

Cool. Just making sure you can see what I see.

Right on.

Whoops. So today is all about probability and you've almost surely encountered this idea before any mathematicians out
there. Almost surely is actually something we can define in mathematics. I'll leave you to Google that for later,
because that's totally not what my lecture is about, but it's a funny little math joke. But first I want to talk to
y'all. I want to get some, like poll the audience questions. What is probability don't do the Google's like what is
probability to you?

Robin chat.

Yeah. The chances of something. Yes, absolutely. Anybody else have some like, ideas about like probability.

It's actually a couple of definitions, which is why I'm asking. Any other thoughts on what probability is nostalgia
kind of agree with that. There's a pragmatic answer, which hands I was all about. He's like, it's the measure of a
likelihood of an event or the chance of an event happening. The odds of what outcome based on all the possible outcomes
are the likelihood of something happening. I love it. We're using likelihood here. So that's really important. There's
also like a more like theoretical answer here for mathematicians. It's a formal system to quantify uncertainty, right?
We're not sure if an event is happening. We're not sure if I met is likely. Yeah. Is there any use probability to
determine its likelihood? Cool.

Why do you care? What probability is Danny? We've been doing all this junk with words. Why do we care about suddenly
math? All of a sudden, well, It's going to have a lot to do their tweet generator. Every day, real world problems deal
with uncertain information or uncertain outcomes. This is something that you'll have to like kind of show off in
software a lot. For example. What if. Can I do like diagnose something or predict the cause given some symptoms, for
example, Like dealing with medical treatment or mechanical repairs. What's the likelihood that the medical treatment
will be. It will be like successful. For example, you hear with like cancer, you have like a 65% rate. Of of getting
rid of all the cancer, right. For mechanical repairs. What's the likelihood that like the part's going to go go like be
totally broken as soon as you install it, or maybe the likelihood of it, like. Wearing out in six months, that's a good
example of how we deal with like probability. In terms of like diagnoses. Our risk assessment. What is the likelihood
that the game stock stock is going to like blow up to like crazy amounts of prices and then dip and crash hard. What's


that.


Or. Or like environmental stuff. What's the, what's the probability that we're all just like in a. Burn up in the
environment is going to go to crap. Right. It was kind of a joke, but like a thing, or how about like product
reliability? You think about like testing a vehicle? What's the likelihood that you're gonna like survive a crash in a
particular vehicle? What's the likelihood you buy like a brand new Oculus and like you get it out of the box and it
totally doesn't work. Three different, like different ways that we can think about these uncertain information. And
uncertain incomes outcomes. George has asked me, Danny, if this is data science or data structures, it's a little bit
of a, it's a little bit of both, you know, I have like many loves in computer science. And of course, if you take any
of my classes, they just like. Crashed together. So, yeah, this is a little data science. For those of you who are on
the DS track. You're gonna like this. Cause I got a lot of sneak previews for you.

Let's talk about like the rules, right? So how, what are the rules around like determining the likelihood of these
types of situations?

So let's think about events of uncertain occurrence. We're gonna call them. We're gonna think of two different events.
I'm going to call them. Event a and event B. Okay. Event a and event to be. So when we talk about probability theory,
we assume these axioms. And you know what that word means by the way, Axiom. No. It's a fancy word. That means
something that we all know. It's a fancy word. That means like things we assume to be true. Or there's a certain truth
things. Yeah. The things that we are just all accepting are true. Okay. So probability theory assumes these axioms.
First one. It's either. Going to never happen. That's a zero. It was all always between the probability of something
has always computed in between one or zero. You're one zeros, like it's never going to happen. One is like it is 100%
certain it will happen. And the probability of any Axiom or any event. Usually lies somewhere in the middle. Right. So
you see zero. Is less than or equal to the probability of an event happening. Less than or equal to one. Which just
means. That the probability of something being certainly true is one. And the probability of something being absolutely
false zero. Always forever and ever. Amen. Okay. This is really important. Really important.

And we can kind of think of it a little bit like a Venn diagram. If you just saw like a math equation here and your
heart stopped. I'm not going to quiz you on this. I promise not going to quiz you on, I'd just like some background
information as to like why we're doing the things that we're doing and why you should care. So, if you wanted to
compute the probability of event a or B happening a or B, we would, then we would take the probability of the event
happening. We would add it to the probability of the B event happening. But now we've kind of got like some overlap
over here. We've. Doesn't overlap that we haven't like subtracted. So we then take the probability of a and B occurring
and subtract that from our, some. And we have the probability of either event happening. Pretty cool. I'm not going to
quiz you on this. But it's kind of like a neat way, kind of think about all this different stuff. Give me one sec. Ah,
that's what I was hoping for. And remember axioms are just like things that we assume are true. Y'all things we assume
are true.

Cool. Any questions here.

Now Myrna. Think about probability. When I think about discrete probability, y'all know this. So we all like games of
chance, discrete probability deals with events that occur in accountable sample space. What do I mean by that? Again,
fancy, fancy math stuff, but this is just like the probability of, you know, Coin flip. Or dice. Or cards or words or
words. When you think about like the probability of where to carry me, think about the probability of rolling a two on
a six sided die. We think about the probability. Of flipping a coin and getting heads. Yeah. Pretty cool. Here's some
pictures, you know, All of these things, but like, why do we care? We're not playing games, obviously in this bathroom,
designing games, we are thinking about whoa. Words are used in my text more often. Words are also discreet. Just like a
dice roll.


Oh,


yeah.


You know what? This is kind of like the website I made back. Last month.


Right, right. Totally. Yeah. You had some like discreet cards about like different. Informational topics in Python. If
I recall correctly. Totally.

So let's talk about a little bit about uniform distribution. Okay. So we have a known finite number of outcomes that
are equally likely to occur in uniform distribution. I think it helps to like see a little picture. What does that
mean? When I roll a dice. Each of the values on the dice. 1, 2, 3, 4, 5, or six. Has an equal probability of, of
actually like showing up when I roll that dice, each event values as a probability of one out of the number of
possibilities. Okay. So if I'm rolling a dice. Check it out. It's got like all the same stuff. Here's an example of
that. Rolling. A fair die that isn't weighted and is 100% fair. A fair. I call this like a Vegas dice, right? Because
it has to be fair because money's on the line. The probability is the same for each of the sides on a fair dice. That's
it.

But when we think about sampling words, Let's look at this little sample that I've got here. When we think about
distributions, where we got here. Got a function called sample. It's taking, in some words, in this case, it's taking
in a list of items, red, yellow, green, and blue. That red, yellow, green, and blue, we're going to use.

You know, make our own sample function by the way, those of you on the second or third page of the tutorial who did
like random dot sample. This is how it's implemented on the backend in Python. So uses random dot random mint. We start
at the index of zero because that's where lists start always. And we, we generate a random integer. Up to the length of
the words minus one. Okay, because it's zero based. So if we have four words in here, Random integer is going to choose
either 0 1, 2 or three C like my fingers, like 0 1, 2 or three four here. Right?

Can I get four different things. So the index is either going to be 0 1, 2 or three, and it's going to return the M
word that is located at the index of the list of words. But the index that we generated, it's guaranteed to work
because we're going to take the length of the words. Minus one, because we're dealing with indices, right? If you
forget minus one, Going to have a bad time. Because zero through four generates five different integers. And if you get
a. For back words of the index of four. No existing, no exist. You're going to get. Index error. Right? Gotta make sure
it's linked to the words. Four minus one. Because we're using a zero‑based index. This is very common. One of the most
common bugs I have found in my career, one of the most common bugs I've found as a teacher. There's little off by one
bugs. They'll get you every time. So when we look at this, what do you notice right off the bat about the words. What
do you notice right off about, about them for some qualities about the list of colors that I have here.

Can anyone tell me.

For the length of the words have different links. Yes.

Anything else about this list of words?


I'll call her. Is


there all colors? I love that. They're missing orange. Absolutely true fact. But what about this fact? Each of these
colors is unique, right? So if I choose a random color, I'm always going to get one. Unique random color.

Now if each of them are unique, couldn't we imagine this situation is like, A funny shaped four‑sided die. And we roll
it. And we roll that funny shaped. Like four‑sided die with colors on it. Each word, each color has equal probability
of being selected, right? Equal probability, because we don't have it showing up in the list. We don't have like three
reds and yellow, green, and blue. That would mess stuff up. So just like Dylan said, Words are sampled. Using uniform
distribution. We're using uniform distribution. Because we have unique words here. Very cool.

Now, let's talk a little bit about word frequencies, right?

Our goal. At least like in our last part of class, you had like a couple of functions that you had to implement. You
had to do a histogram, you had to do frequency and you had to do the count of the unique words. So I ask now how many
distinct words are in a text sample? Ah, you could figure out how many unique words are there. What are the frequencies
of those individual words? That's a histogram, just kind of like a little bit of review, but from like a mathematical
perspective.


So


I'm going to teach you some cool new data, science probability NLP kind of words. Okay. That's like natural language
programming. That's like a thing about it as the computer science of words. Ah, yeah, sort. Distinguished between two
new vocabulary terms today, tokens and types.

Tokens. That's the occurrences of the words.

Versus types, which are distinct words. Red yellow. Purple blue. Those are types.

But when I use the sentence. One fish, two fish, red fish, blue fish. We have eight tokens here.

But we only have five words. I have five words that show up. So I was wondering. Because for me, it's a little bit
easier. Like when I think about mathematics to kind of like put it in terms of programming, because that's like where I
come from. Can you think about like this relationship between types and tokens? Does it remind you about any like
relationship that you might see an object oriented programming? I don't remind anybody of anything.

When


people think they think about the coin token.


And this case we're gonna use the NLP version of the word. Which is an occurrences of words as you current. And he
wouldn't think about like, How we might. Kind of think about tokens and types in an Oop


context.


Oh, nice classes. Type is like a class. And a token is like instances of that class one class. Creates many instances,
right? One type. With many tokens. Check it out. Very nice. Very nice. Totally. I'm not going to quiz you on this
either. It's just like a cool way to like, think about it. That's why I put like instances there. Right? How many
instances of the word. Harry are in your sample text. If I count them up and I find dates. You have eight tokens. Of
Tyler Perry ha. Right.

So let's think about this in terms of distribution. We have done this already. We're just using new vocabulary terms to
define it. We need to count tokens in a word histogram. We need to count instances of the word. In our histogram. So
check it out is one fish, two fish, red fish, blue fish. It's going to haunt you forever.

Shake it out. Here's like a nice little like graphical interface, nice little bar chart. And you can see we've counted
fish four times. I even like made it colorful. It's pretty cool. And you can really like tell that these are unique
instances of words and each one over here on the side, the word.

That's the type. The count. Tokens instances. Yeah. Cool.

So let's talk about sampling these distributions a little bit.

Checking my time. It always goes so fast. So observed word tokens. Have non‑uniform distribution just means like some
words show up more than other words. When we talk any language to each other. Right.

So let's think about our text. One more time. One fish, two fish, red fish, blue fish. If I were to make like a little
manual style histogram for that, I might call it a variable, like word counts. I might have. One is the key. And of
course there's one instance of that. Fish is another key and there's four inches of that. Fish as a token. Or to me,
fish is a type and for tokens, another way of thinking of it. And today your goal will be in the fourth part of the
tutorial to work together. To create. And fill in a sample by frequency. Function that takes in your histogram. And is
able to select a word based on frequency. And the idea here is. I don't know. Let's think about like our sentence. One
fish, two fish, red fish, blue fish. I said fish so many times. I should see when we roll this silly Dr. Seuss dye that
I've created for y'all. I should see. Fish more often when I generate a random word from that sentence compared to say
the word one, which only occurs once. Another way to think of it is your, your function should be about four times as
likely to fit out the spit out fish as it is to spit out the word blue. And if we called this function say a hundred
times, and we kept track of all the results, what random word was generated here? We should see the word fish about 50
times, but not necessarily. Exactly right. There is a little randomness in here. We might hit convergence if we like, I
dunno, called it. 500 or a thousand times. The idea here is you should intuitively see these words that are appearing
more often.

When you generate them.

So the goal here today is like, thinking about how do you sample words using their observed frequencies. So that we get
fish more often when we generate a word rather than Ooh. That's going to be important because if I want to make, like,
if I want to like feed and algorithms and sample tags and then make it talk like that sample text, gosh, I'm going to
have to use the words that this person used most often. I was laughing when I was thinking about it, like a histogram
of what my words would generate. And sometimes I feel like there'd be like a lot of like stop words, like, like, or,
and, or the other, but there'd also be like a lot of really funny words, like nice word. Bad‑ass like things that I
say, like really commonly. That's show up, maybe like tool for the job, things like that. Like common Danny phrases.
They're going to show more often because like that's part of my vernacular. It's part of like my dictionary that I use
a lot.

So I'm going to give you some ideas, some cool ideas for how you could like work together in pairs or groups to sample,
to sample using word frequencies. For example. One common one. You could duplicate the words in the histogram by their
multiplicity. Like how many times they show up. And then sample that list with uniform distribution. Standby on that
one. Another way you could probably do it is by accumulating the word counts through the list. And finding where a
uniform random number splits that. So, you know where to add other words. And there are lots of other ideas. But
remember just like when we implemented histograms. And we like thought about today. All the different, like. Pros and
cons of the different methodologies. Some of these ideas are better than others. For example.

Think about like number one. When did the kind of like. Slower. Wouldn't it be more? But do you require more time? When
you require more space. If I duplicated words.

What if you had like a really big text, like the last area of our book is like 800 pages. If you duplicated 800
patients. For the texts and like needed to run your program efficiently. That's going to be a really difficult, it's
going to take like a bunch of time to sample. That when you deal with duplication. But I'll show you a little technique
here shortly. That you could use to maybe accumulate those counts. Okay.

There are lots of other ways, too. For those of you there, like Danny has this data science class. Yes. Maybe a little,
there are some possible future directions. You can take this, everything I teach you. I have done in real life and like
have used as building blocks to bigger, better, more awesome or things. Let me highlight the building blocks of more
awesome or things you can do with this. For example colocations and Ngrams, you don't know those words. That's cool.
I'm not gonna quiz you on it. Come see cash for like many of his data science classes. To learn more about these things
I'm highlighting here, like conditional probability. Markov models and chains. We'll be doing that together. That'll be
crazy fun.

Text generation in classification. We're doing the generation in this class, but text classification, I'm going to
happen in a different data science course, because I could talk for seven weeks about that and still not be done. Or if
you're like crazy advanced and you like get really into like Markov chains, you there's something called smoothing and
back off that you would, that you would apply to higher order mark off chains to like, make it even better. Those of
you who like go further on in the tutorial or get like really, really into the later parts of the tutorial might maybe,
maybe just maybe if you get like super duper crazy into it and you have lots of time, you might look at that. It's a
really cool, this tutorial is like one size fits all. You can go as far as you want with it. And I encourage you to do
that. But all of these things are things that you like might, might comply like later on in life or in class or
whatever.

So today's milestone is to get started with page four, which is stochastic sampling. That just means sampling a word.
Right. So I want to kind of go back just a little bit to.

We had here, which was like the ideas. So we've talked about duplicating. This might have some downsides, right? It
might like take up a bunch of like space because you implication always takes up space. That means have a copy of a
list or have a copy of a data structure. Ooh, duplication's a little scary. You could accumulate word counts to the
list. Let's go like hard to think


about


isn't it. Accumulate word council. We have a list. So let's start with like a little


example.


And I promise they're going to like go even more in depth with us on Friday. And we're going to have some lab time to
work on that page four as well on Friday. Let's talk about like what it might look like to accumulate word counts
through lists. This is like, whoa, I remember first hearing about this and thinking, Hmm. What the heck does that mean
accumulates? So let's check it out. I got some pictures here. Kinda wanna like, be able to draw on my iPads. I'm going
to use that instead.

Oop. Oh nice. Like. Like just pops right up. Cool.

And see if you can see it though. You share desktop one. Nice. All right. So here again. You'd have to like, read this
on a piece of paper. Y'all like real quick. Not fancy iPad yet. Here. We've got a histogram. And it's a histogram for
one fish, two fish, red fish, blue fish told you it's going to haunt you forever. You know, like totally be Dr. Susan
and up in interviews. It'll be


cool though.


So maybe we've got like a histogram and we're counting how many times these words occur. Let me see if I can like do
editing and like have a pen go on here.

Ooh. Okay. Sorry. I never used this interface, but it's all work. So we've got one fish, two fish, red fish, blue fish.
We've got the key right here. Oh, let's use a red and like a highlighter and like, yeah, you got keys. One fish, two
red and blue. Is there a keys? They were using the dictionary data structure yet. And then of course the values, which
are the count of how many, how many times this word is occurred in our text. One is occurred one time fish, four times
and so on and so forth. I engineered this text for a reason folks, because it really shows you really shows you how
like histogram builds it up. So one thing I like to kind of think of when I think of accumulating, come back to this
slide, like real, real quick here. I think about accumulating the word counts through the list. You could think of it
as. Number line number line here. So we've gotten our number line is our keys. I'll show you in yellow, one fish, two
red and blue. Here's our keys and those keys. We can store like.

The values of in‑store the values that we instilled the distillation. So one occurs one time. So it takes up. Hmm. And.
And these green here. It takes up this amount of space.

We got fish.

Camp this amount of space. Yet too.

Red. And blue. You can kind of think of it, like throwing a dart. When you're inserting words into this list, you're
trying to figure it out. Yeah. Where should you add other words? So here, we've got a total of eight tokens. Remember
that's instances, instances. So this all adds up to eight.

Right. 4, 5, 6, 7, 8. Yup. Works great. Tokens instances or the sum of the values in your histograms, the number of
tokens. And we've got like five types. I kind of use like, Yellow to highlight that we have five types. Those are the
number of keys in your histogram. If using a dictionary data structure. Getting about inserting you think about just
throwing it arts. Anywhere on this number line and say, And up right here.

We've got. The place where we can like insert things so we can accumulate based on the values. So one appears one time.
So you use red for this. So it takes up 0 3, 1 on the number line. Fish occurs four times. So it takes up
1, 2, 3, 4, 5. One to five on the number line that makes some fence posts here. So it's like easier to see.

We got the same thing here for two starting here at five. Red takes up six to seven, seven to eight. So if we think
about like the distillation of this or the accumulation, David's the accumulation. We're always going to look at these
fence posts, check this out, let me try and do black. You're always going to look at these fence posts. Oop.

Right here. I'm going to use those fence posts to the notes where the word one occurs. Where the word fish occurs, et
cetera. Thusly and make it a lot easier to insert new stuff. So let's check it out. Here in our distillation. We've got
the key one.

Right here. And now on the right edge of the fence post. As we're going to keep track of where these occur. One on the
right edge of the center. Post is one. On the right edge of the French post 5, 6, 7, and eights. And you can use this
strategy. Help you think about your fourth page of your tutorial? I'm going to be doing some more in‑depth drawings on
this particular subject on Friday. But what I'd like to do now is just kind of introduce you to the tutorial, show you
how like this might apply to it. And like what section is important to you? I'd also like to tell you. This is where it
gets a little tough. Y'all. For real. Even for those of you who are like experienced programmers and know y'all are out
there. This might be kind of the time where it's like a little bit of a thinker. I highly recommend several strategies
to get through this part of the tutorial. You can team up with a friend. You know that I'm like totally cool with that.
As long as it's your own fingers moving on your own keyboard and everybody's implementing their own version. You could
reach out to our TA David, who is be more than happy to help you think about how to implement this. You could reach out
to the class channel. Any time


and say, Hey, does anyone like get


this? And you could work together with like a new friend that's in class that you haven't before. And there's always
the last ditch effort of ask Danny, but let's wait like till Friday, let's like get some good struggle in there and see
if we can implement. It's like little fence posts, strategy. So let's see how it like applies to our tutorial. So we'll
be doing this page or the tutorial, which I like drop into chat. Huh. That's so cool.

This page of the tutorial. So we've generated our histograms, which are word frequency, distributions, and now we've
got to like pull out the most common ones and make sure that those show up more.

For example, like in this tutorial, it makes a joke that like our tweet generator or our legs sentence generator may
not be able to speak as well as Siri, for example, but we can approximate some English grammar by using more common
words in our sentences. So we talked about stochastic sampling. That just means taking an element from a given
collection at random. Right. So that just means like, let's go back to our sides real quick.

Sampling. We also have this example, right. Sample by frequency. And then we have, oh, and put up the wrong one.

This one, because our sample of words. We do a sample. That just means it takes a rant. Take a random word. So, how do
we make sure we take, like when we get samples, we get more frequently occurring birds. So here. Because each word is
unique. We have like, The same probability of getting anywhere. It's like a four‑sided die, but yours is a little bit
different, right? Some words, the court more frequently than others. So your task is to write a function that takes in
a histogram. However, you've structured it. However yours works and return a single word at random. The first thing it
should do is just return a word at random from your text things. It's cool to build things in like an MVP style. Cool.
To build stuff up. Right? So first return a random word from your body of text. Don't worry about the frequency of
them. Just return a random word. Think back to part two of the tutorial. Look at that code that you implemented. If you
need a leg up, it's totally okay to use your own code that you already wrote. I'm a big fan of that.

So here, this is the example with Sampa dot PI got one fish, two fish, red fish, blue fish. It's just returning a
random word, whatever.

Then once you have that working, we need to like, kind of change our script. So it'll print. Like it's going to print
the word fish more often than the word red. So walk you through the tutorial to show you, like, go check it out. The
probability. Remember our probabilities are always between zero and one, which is why you get numbers like this in the
tutorial, right? We've got a 0.1, two, five chance of one, two red and blue occurring, which is one eighth, by the way,
because they're eight words. Each one of those appears once. So the probability is one eighth, whereas with fish
appears four times. So probability is four eights, right? Number of times it occurs over the like length of your list,
right? The length of your list. Number of times, the word occurs over the length of the list. That's how we got that.
When we do four divided by eight, we at 0.5.

So got a 50% like chance for fish and a 12.5% chance for all the rest. If you're wondering where that comes from, just
taking that probability and times it by a hundred per cent, 100. Yeah. So you can see there's a lot of different, like
many ways to use these relative probabilities. And the goal here is to like devise your own strategy.

Kind of like thinking, whoa, I'm feeling a little overwhelmed by this read up on the help. What is the stochastic
madness section? I'm kind of aware that I definitely kept you have like a minute or two longer than I need to, but read
through this part of the tutorial at the very least, I want you to have read the tutorial. And at the very least, then
when you're generating a random word from your dataset, your body of text, your Corpus to use the official words, the
very least I want that by Friday when I see you again, right then we'll do some more cool number line stuff and kind of
get like, even more in depth with this drawing, how this strategy of accumulating and accumulating. Like we see in our
slide here, whoops, boop, accumulating all the way down here.

So we're going to go through the strategy of accumulating those word counts to the list. Then finding where a uniform,
random numbers splits it, run. And talk about that more. So go ahead and get going. Folks. Can't wait to see you again
on Friday. Make sure you have that random word from your Corpus and I'll see you later. Bye everybody. Peace out. Sorry
for keeping you a little longer, my bad.

Or do you actually about your recorded video? I just want to review it, Whereas Those, Yeah, you can find them and all
my videos that I've ever recorded at bit dot L Y and I'll put this in chat to proxy vids right there. That's the one.

Okay. I think it's.